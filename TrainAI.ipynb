{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYu2O9gGLLT5"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as tfk\n",
        "import tensorflow.keras.layers as layers\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ВВЕДИТЕ ПУТЬ К JSON-ДАТАСЕТУ\n",
        "JSON_PATH = 'ВАШ ПУТЬ'\n",
        "import json\n",
        "\n",
        "with open(JSON_PATH, 'r', encoding='utf8') as f:\n",
        "  data = json.load(f)\n",
        "  f.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-4YZYrAzr73",
        "outputId": "8963b0a6-0f8b-4a87-d092-ef61a370c6be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для докомплектации пустыми векторами матрицы поездов\n",
        "def find_max_train_count(situations):\n",
        "    max_train_count = 0\n",
        "    full_timetable = []\n",
        "\n",
        "    # Находим максимальное количество поездов\n",
        "    for situation in situations:\n",
        "        full_timetable = situation['full_timetable']\n",
        "        train_count = len(full_timetable)\n",
        "\n",
        "        if train_count > max_train_count:\n",
        "            max_train_count = train_count\n",
        "    return max_train_count\n",
        "\n",
        "# Конвертер временных интервалов\n",
        "def convert_time_intervals(time_intervals):\n",
        "    converted_arr = []\n",
        "    converted_dep = []\n",
        "    for interval in time_intervals:\n",
        "        start_time, end_time = interval.split(' - ')\n",
        "        start_hour, start_minute = map(int, start_time.split(':'))\n",
        "        end_hour, end_minute = map(int, end_time.split(':'))\n",
        "\n",
        "        total_start_minutes = start_hour * 60 + start_minute\n",
        "        total_end_minutes = end_hour * 60 + end_minute\n",
        "\n",
        "        converted_arr.append(total_start_minutes)\n",
        "        converted_dep.append(total_end_minutes)\n",
        "\n",
        "    return converted_arr, converted_dep\n",
        "\n",
        "# Функция для приведения данных о поездах в читаемый вид\n",
        "def transform_train_data(data, max_train_count):\n",
        "    transformed_data = []\n",
        "\n",
        "    zero_matrix = np.zeros((max_train_count, 4, 7))\n",
        "    # route - free_carriage - time_arr - time_dep\n",
        "    for i, entry in enumerate(data.items()):\n",
        "      route = list(map(int, entry[1][\"route\"])) + [0] * (7 - len(entry[1][\"route\"]))\n",
        "      free_carriage = list(map(int, entry[1]['free_carriage'])) + [0] * (7 - len(entry[1]['free_carriage']))\n",
        "      time_arr = convert_time_intervals(entry[1]['timetable'])[0] + [0] * (7 - len(entry[1]['timetable']))\n",
        "      time_dep = convert_time_intervals(entry[1]['timetable'])[1] + [0] * (7 - len(entry[1]['timetable']))\n",
        "\n",
        "      info_list = [route, free_carriage, time_arr, time_dep]\n",
        "      for x in range(len(zero_matrix[i])):\n",
        "        for y in range(len(zero_matrix[i][x])):\n",
        "          zero_matrix[i][x][y] = info_list[x][y]\n",
        "\n",
        "    return zero_matrix\n",
        "\n",
        "\n",
        "max_train_count = find_max_train_count(data)\n",
        "\n",
        "def normilize(data):\n",
        "  normilized_stations_data = []\n",
        "  normilized_train_data = []\n",
        "\n",
        "  global max_train_count\n",
        "  for situation in data:\n",
        "      stations_data = situation['stations']\n",
        "      stations = {key: value for key, value in stations_data.items()}\n",
        "\n",
        "      N = 7\n",
        "      unused_vagons_per_situation = np.zeros((N, N))\n",
        "\n",
        "      for source_station, carriages_in_order in stations_data.items():\n",
        "          source_station_index = list(stations_data.keys()).index(source_station)\n",
        "          for carriage_destination, num_carriages in enumerate(carriages_in_order):\n",
        "              destination_station_index = carriage_destination\n",
        "              if source_station_index != destination_station_index:\n",
        "                  unused_vagons_per_situation[source_station_index][destination_station_index] = num_carriages\n",
        "\n",
        "      normilized_stations_data.append(unused_vagons_per_situation)\n",
        "\n",
        "      trains_data = situation['full_timetable']\n",
        "\n",
        "      sit_norm_train_data = transform_train_data(trains_data, max_train_count)\n",
        "      normilized_train_data.append(sit_norm_train_data)\n",
        "\n",
        "\n",
        "  train_pack = [normilized_stations_data[:90000], normilized_train_data[:90000]]\n",
        "  test_pack = [normilized_stations_data[90001:], normilized_train_data[90001:]]\n",
        "\n",
        "  return train_pack, test_pack\n"
      ],
      "metadata": {
        "id": "H8J5vf0q9KOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRX9LBEvZ3V6"
      },
      "outputs": [],
      "source": [
        "# Подготовка к реализации нейросети\n",
        "\n",
        "train_pack, test_pack = normilize(data)\n",
        "del data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphNeuralNetwork(tfk.Model):\n",
        "    def __init__(self, num_stations=7, num_train_vectors=43):\n",
        "        super(GraphNeuralNetwork, self).__init__()\n",
        "        self.num_stations = num_stations\n",
        "        self.num_train_vectors = num_train_vectors\n",
        "        self.shape_output = (self.num_train_vectors, 7, 7)\n",
        "\n",
        "        self.input_train_vectors = layers.Input(shape=(self.num_train_vectors, 4, 7), name='input_train_vectors')\n",
        "        # self.create_mask()\n",
        "\n",
        "        self.model = self.create_model()\n",
        "\n",
        "    # def create_mask(self):\n",
        "    #     self.mask = np.ones_like(self.input_train_vectors, dtype=np.int32)\n",
        "    #     for i in range(self.input_train_vectors.shape[0]):\n",
        "    #       for j in range(self.input_train_vectors.shape[1]):\n",
        "    #           for k in range(self.input_train_vectors.shape[2]):\n",
        "    #               if self.input_train_vectors[i, j, k] == 0:\n",
        "    #                   self.mask[i, j, k] = 0\n",
        "    #                   self.mask = tf.constant(self.mask, dtype=tf.float32)\n",
        "\n",
        "    def custom_loss(initial_matrix):\n",
        "      def loss(y_true, y_pred):\n",
        "          return tfk.backend.sum(tfk.backend.abs(initial_matrix - y_pred))\n",
        "\n",
        "      return loss\n",
        "\n",
        "    def create_model(self):\n",
        "        reshaped_input_train_vectors = layers.Reshape((self.num_train_vectors * 4, 7), name='preLSTM_reshape')(self.input_train_vectors)\n",
        "\n",
        "        lstm_layer = layers.LSTM(16, return_sequences=True)(reshaped_input_train_vectors)\n",
        "        flat = layers.Flatten()(lstm_layer)\n",
        "        dense_layer = layers.Dense(16, activation=\"relu\")(flat)\n",
        "\n",
        "        hidden_layer1 = layers.Dense(32, activation=\"relu\")(dense_layer)\n",
        "        hidden_layer2 = layers.Dense(16, activation=\"relu\")(hidden_layer1)\n",
        "\n",
        "\n",
        "        output_layer_prereshape = layers.Dense(self.num_train_vectors * 7 * 7, activation=\"softmax\", name=\"output\")(hidden_layer2)\n",
        "        output_layer = layers.Reshape(self.shape_output, name='final_reshape')(output_layer_prereshape)\n",
        "\n",
        "        return tfk.Model(inputs=[self.input_train_vectors], outputs=output_layer)\n",
        "\n",
        "model = GraphNeuralNetwork(7, 49)"
      ],
      "metadata": {
        "id": "1FN_k6R8sDlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BCn3SztVsDq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N7oFIgTIw_gA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VBxHReijw_i1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PIXQgXX0w_l0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########################################################################################\n",
        "# Реализация матмодели. Из-за специфики задания пришлось отказаться в пользу нейросети #\n",
        "########################################################################################\n",
        "\n",
        "\n",
        "# from scipy.optimize import linprog\n",
        "\n",
        "# from pulp import LpProblem, LpVariable, lpSum, LpMinimize, LpStatus\n",
        "\n",
        "# initial_matrix = unused_vagons_per_situation\n",
        "\n",
        "# # Оптимизационная задача\n",
        "# model = LpProblem(name=\"railway_optimization\", sense=LpMinimize)\n",
        "\n",
        "# # Переменные решения\n",
        "# var = [[[LpVariable(name=f\"var_{i}_{j}_{k}\", lowBound=0, cat=\"Integer\") for k in range(7)] for j in range(7)] for i in range(len(trains_data))]\n",
        "\n",
        "# # Определяю целевую функцию (минимизация суммарной разницы)\n",
        "# model += lpSum(initial_matrix[j][k] - var[i][j][k] for i in range(len(trains_data)) for j in range(7) for k in range(7))\n",
        "\n",
        "# # Добавляем ограничения на количество вагонов на каждой станции\n",
        "# for train_index, trains in trains_data.items():\n",
        "#     for train in trains:\n",
        "#         model += lpSum(var[int(train_index)][1][1] for j in range(7)) <= train[int(train_index)][\"available_carriages\"]\n",
        "\n",
        "# # Добавляем ограничения на перевозку вагонов по маршруту каждого поезда\n",
        "# for train_index, train in trains_data.items():\n",
        "#     for j in range(len(train[\"route\"]) - 1):\n",
        "#         from_station = train[\"route\"][j] - 1\n",
        "#         to_station = train[\"route\"][j + 1] - 1\n",
        "#         model += lpSum(var[train_index][from_station][to_station]) == train[\"available_carriages\"][from_station]\n",
        "\n",
        "# # Решаем оптимизационную задачу\n",
        "# model.solve()\n",
        "\n",
        "# # Выводим результаты\n",
        "# if LpStatus[model.status] == \"Optimal\":\n",
        "#     print(\"Оптимальное распределение вагонов:\")\n",
        "#     for i in range(len(trains_data)):\n",
        "#         for j in range(7):\n",
        "#             for k in range(7):\n",
        "#                 print(f\"Поезд {i+1}, станция {j+1} -> {k+1}: {var[i][j][k].value()}\")\n",
        "# else:\n",
        "#     print(\"Задача не имеет оптимального решения.\")\n"
      ],
      "metadata": {
        "id": "PNQXGaDP-7Sk"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
